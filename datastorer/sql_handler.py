import pandas as pd
from sqlalchemy import and_
from sqlalchemy.orm.query import Query

from datastorer.data_handler import DataHandler
from datastorer.database import db_session, Base
from utility.constants import DATA_SOURCE_TYPE, DATA_LOCATION, LEFT_KEYS, RIGHT_KEYS


class SqlHandler(DataHandler):
    def __init__(self, data_sources):
        self.data_sources = data_sources
        for data_source in self.data_sources:
            table_name = data_source[DATA_SOURCE_TYPE]
            table_class = self.get_class_name_from_table_name(table_name)
            data_source.update({DATA_LOCATION: table_class})
        self.combined_data_table = self.build_combined_data_table()

    @staticmethod
    def get_class_name_from_table_name(table_name) -> str:
        """
        Camel-cased class name generated by sqlalchemy codegen doesn't match the sql table name. Fetch the class name based on matching class table name
        :param tablename str
        :return: class name
        """
        for class_ in Base._decl_class_registry.values():
            if hasattr(class_, "__tablename__") and class_.__tablename__ == table_name:
                return class_
        raise KeyError(
            f"Sqlalchemy class not found corresponding to table {table_name})"
        )

    def build_combined_data_table(self):
        """
        This takes the tables specified in self.data_sources and combines them into one easily referenceable selectable.
        This is essentially a query view- performing the joins and getting all columns that can be filtered in a query.

        :return: SqlAlchemy DeclarativeMeta selectable class
        """
        # first build a query that will get all of the columns for all of the requested tables
        query = db_session.query(
            *[data_source[DATA_LOCATION] for data_source in self.data_sources]
        )
        # columns_to_get = []
        # for data_source in self.data_sources:
        #     table_class = data_source[DATA_LOCATION]
        #     table_columns = table_class.__table__.columns
        #     # columns_to_get.extend([getattr(table_class, c.name) for c in table_columns])
        #     columns_to_get.extend([c for c in table_columns])
        # query = db_session.query(*columns_to_get)
        # Assumption: All joins link to IDs in first table, not IDs that were added in previous joins
        for i, data_source in enumerate(self.data_sources):
            table_class = data_source[DATA_LOCATION]
            if i > 0:
                # how do we join in this data source to the previous ones in the query
                previous_data_source = self.data_sources[i - 1]
                previous_table_class = previous_data_source[DATA_LOCATION]
                # todo: join on multiple keys
                matched_keys = zip(data_source[LEFT_KEYS], data_source[RIGHT_KEYS])
                join_clauses = [
                    (
                        getattr(previous_table_class, matched_key[0])
                        == getattr(table_class, matched_key[1])
                    )
                    for matched_key in matched_keys
                ]
                query = query.join(
                    data_source[DATA_LOCATION],
                    and_(
                        *join_clauses
                    ),  # on clause matches corresponding table columns
                )

        class QueryView(Base):
            # defines the selectable class for the query view
            __table__ = query.selectable.alias()

        return QueryView

    def get_column_names(self):
        """
        :return: a list of the column names in the table referenced by the handler
        """
        # todo: these are prefixed with table_name of the sub table in combined_data_table
        # return list(self.combined_data_table().__table__.columns.keys())
        raise NotImplementedError("This function is not used meaningfully, delete?")

    def get_column_data(self, columns: list, filters: dict = None) -> dict:
        """
        :param columns: A complete list of the columns to be returned
        :param filters: Optional dict specifying how to filter the requested columns based on the row values
        :return: a dict keyed by column name and valued with lists of row datapoints for the column
        """
        query = db_session.query(
            *[getattr(self.combined_data_table, col) for col in columns]
        )

        # raise NotImplementedError
        # # todo: filter by inequality
        # # Build the list of filters to apply to the data
        # for filter_column, filter_value in filters.items():
        #     # filter is a single item, evaluate with sql's equality statement
        #     if isinstance(filter_value, (int, float, str)):
        #         query = query.filter(
        #             getattr(self.table_class, filter_column) == filter_value
        #         )
        #     # filter is a list of possible items, evaluate with sql's "is in" statement
        #     elif isinstance(filter_value, (list, dict)):
        #         query = query.filter(
        #             getattr(self.table_class, filter_column).in_(filter_value)
        #         )
        # response_rows is a list of tuples
        response_rows = query.all()
        # use pandas to read the sql response and convert to a dict of lists keyed by column names
        response_dict_of_lists = pd.DataFrame(response_rows).to_dict(orient="list")
        return response_dict_of_lists

    def get_column_unique_entries(self, cols: list) -> dict:
        """
        :param cols: a list of column names
        :return: A dict keyed by column names and valued with the unique values in that column
        """
        unique_dict = {}
        for col in cols:
            query = db_session.query(getattr(self.combined_data_table, col)).distinct()
            response = query.all()
            # todo: note we're dropping none/missing values from the response. Do we want to be able to include them?
            unique_dict[col] = [r[0] for r in response if r[0] is not None]
        return unique_dict
